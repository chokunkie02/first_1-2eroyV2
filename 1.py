# 1. ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Library ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏±‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• (‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏•‡∏á‡πÉ‡∏ô Session ‡∏ô‡∏µ‡πâ)
# !pip install llama-cpp-python

# from google.colab import drive
# drive.mount('/content/drive')

from llama_cpp import Llama
import json

# ---------------------------------------------------------
# 2. ‡∏Å‡∏≥‡∏´‡∏ô‡∏î Path ‡πÇ‡∏°‡πÄ‡∏î‡∏• (‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ß‡πâ)
# ---------------------------------------------------------
# ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏ô Drive ‡πÉ‡∏´‡πâ‡∏î‡∏µ‡∏ô‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö ‡∏ß‡πà‡∏≤‡∏ä‡∏∑‡πà‡∏≠ model-unsloth.Q4_0.gguf ‡∏´‡∏£‡∏∑‡∏≠ qwen2.5...
model_path = "assets/models/model-unsloth21.Q4_0.gguf"

print(f"ü§ñ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏≤‡∏Å: {model_path} ...")

try:
    # ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏Ç‡πâ‡∏≤ RAM
    llm = Llama(
        model_path=model_path,
        n_ctx=2048,      # ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥‡∏ö‡∏£‡∏¥‡∏ö‡∏ó
        n_gpu_layers=-1, # ‡πÉ‡∏ä‡πâ GPU ‡∏ä‡πà‡∏ß‡∏¢‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•
        verbose=False    # ‡∏õ‡∏¥‡∏î Log ‡∏£‡∏Å‡πÜ
    )
    print("‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß! ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ó‡∏î‡∏™‡∏≠‡∏ö")
except Exception as e:
    print(f"‚ùå ‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠ ‡∏´‡∏£‡∏∑‡∏≠‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏°‡πà‡∏ú‡πà‡∏≤‡∏ô: {e}")
    print("‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö path ‡πÉ‡∏ô Google Drive ‡∏≠‡∏µ‡∏Å‡∏ó‡∏µ‡∏ô‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö")

print("="*50)

# ---------------------------------------------------------
# 3. ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏î‡∏™‡∏≠‡∏ö (‡∏à‡∏≥‡∏•‡∏≠‡∏á System Prompt ‡πÅ‡∏ö‡∏ö‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏ï‡∏≠‡∏ô‡πÄ‡∏ó‡∏£‡∏ô)
# ---------------------------------------------------------
def test_model(text_input):
    # System Prompt: *** ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏ï‡∏≠‡∏ô‡πÄ‡∏ó‡∏£‡∏ô‡πÄ‡∏õ‡πä‡∏∞‡πÜ ‡∏´‡πâ‡∏≤‡∏°‡πÄ‡∏û‡∏µ‡πâ‡∏¢‡∏ô ***
    # ‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå train.jsonl ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì
    system_msg = "‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡πÅ‡∏¢‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏≤‡∏¢‡∏à‡πà‡∏≤‡∏¢‡πÄ‡∏õ‡πá‡∏ô JSON: item, qty, unit_price, category"

    # ‡∏à‡∏±‡∏î Format Prompt ‡πÅ‡∏ö‡∏ö ChatML (‡∏ó‡∏µ‡πà Qwen ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à)
    full_prompt = f"""<|im_start|>system
{system_msg}<|im_end|>
<|im_start|>user
{text_input}<|im_end|>
<|im_start|>assistant
"""

    # ‡∏™‡∏±‡πà‡∏á‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ï‡∏≠‡∏ö
    output = llm(
        full_prompt,
        max_tokens=512,      # ‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡∏ó‡∏µ‡πà‡πÑ‡∏ß‡πâ‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡∏¢‡∏≤‡∏ß‡πÜ (‡∏Å‡∏£‡∏ì‡∏µ‡∏°‡∏µ‡∏´‡∏•‡∏≤‡∏¢‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£)
        stop=["<|im_end|>"], # ‡∏´‡∏¢‡∏∏‡∏î‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏à‡∏ö‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ
        echo=False,
        temperature=0.1,     # ‡∏ï‡∏±‡πâ‡∏á‡∏ï‡πà‡∏≥‡πÜ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥ ‡πÑ‡∏°‡πà‡∏°‡∏±‡πà‡∏ß
        top_k=40,
        repeat_penalty=1.1
    )


    result = output['choices'][0]['text'].strip()

    print(f"üìù ‡πÇ‡∏à‡∏ó‡∏¢‡πå: {text_input}")
    print(f"ü§ñ ‡∏ï‡∏≠‡∏ö : {result}")
    print("-" * 50)

# ---------------------------------------------------------
# 4. ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ó‡∏î‡∏™‡∏≠‡∏ö! (‡πÉ‡∏™‡πà‡πÇ‡∏à‡∏ó‡∏¢‡πå‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ)
# ---------------------------------------------------------

# ‡πÇ‡∏à‡∏ó‡∏¢‡πå‡∏õ‡∏£‡∏≤‡∏ö‡πÄ‡∏ã‡∏µ‡∏¢‡∏ô‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏™
test_model("‡∏ú‡∏°‡∏Å‡∏¥‡∏ô‡∏Ç‡πâ‡∏≤‡∏ß‡∏Å‡∏∞‡πÄ‡∏û‡∏£‡∏≤4‡∏à‡∏≤‡∏ô ‡∏à‡∏≤‡∏ô 60 ‡∏ö‡∏≤‡∏ó‡∏Å‡∏±‡∏ö‡∏Å‡∏¥‡∏ô‡∏ô‡πâ‡∏≥‡∏°‡∏∞‡∏°‡πà‡∏ß‡∏á‡πÑ‡∏õ 1 ‡πÅ‡∏Å‡πâ‡∏ß‡πÅ‡∏Å‡πâ‡∏ß 35")

# ‡πÅ‡∏ñ‡∏°: ‡∏•‡∏≠‡∏á‡πÄ‡∏ó‡∏™‡πÅ‡∏ö‡∏ö‡∏™‡πÅ‡∏•‡∏á‡πÜ ‡∏î‡∏π‡∏î‡πâ‡∏ß‡∏¢
test_model("‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Ñ‡∏∑‡∏ô‡∏Å‡∏¥‡∏ô‡πÄ‡∏´‡∏•‡πâ‡∏≤‡πÑ‡∏õ 1500 ‡πÄ‡∏¢‡∏≠‡∏∞‡∏ä‡∏¥‡∏ö‡∏´‡∏≤‡∏¢")